Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
C:\Users\lvcha\miniconda3\envs\mmsd2\lib\site-packages\transformers\optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
Epoch:   0%|                                                        | 0/10 [00:00<?, ?it/s]
Iter (loss=X.XXX):   0%|                                           | 0/620 [00:00<?, ?it/s]






















































































































































































































































































































































































































































Epoch:   0%|                                                        | 0/10 [22:51<?, ?it/s]
Traceback (most recent call last):
  File "src/main.py", line 111, in <module>
    main()
  File "src/main.py", line 106, in main
    train(args, model, device, train_data, dev_data, test_data, processor)
  File "D:\users\lvcha\Documents\万恶之源研究生版\毕业相关\多模块\MMSD2.0\src\train.py", line 115, in train
    inputs = build_bert_resnet_inputs(processor, text_list, image_list, args.max_len, device)
  File "D:\users\lvcha\Documents\万恶之源研究生版\毕业相关\多模块\MMSD2.0\src\train.py", line 30, in build_bert_resnet_inputs
    images.append(image_transform(img.convert("RGB")))
  File "C:\Users\lvcha\miniconda3\envs\mmsd2\lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
  File "C:\Users\lvcha\miniconda3\envs\mmsd2\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\lvcha\miniconda3\envs\mmsd2\lib\site-packages\torchvision\transforms\transforms.py", line 346, in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
  File "C:\Users\lvcha\miniconda3\envs\mmsd2\lib\site-packages\torchvision\transforms\functional.py", line 474, in resize
    return F_pil.resize(img, size=output_size, interpolation=pil_interpolation)
  File "C:\Users\lvcha\miniconda3\envs\mmsd2\lib\site-packages\torchvision\transforms\functional_pil.py", line 252, in resize
    return img.resize(tuple(size[::-1]), interpolation)
  File "C:\Users\lvcha\miniconda3\envs\mmsd2\lib\site-packages\PIL\Image.py", line 2193, in resize
    return self._new(self.im.resize(size, resample, box))
KeyboardInterrupt